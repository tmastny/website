---
title: MRP Using Stan, brms, and tidybayes
author: ~
date: '2017-11-20'
slug: multilevel-mrp-tidybayes-brms-stan
categories: []
tags: []
description: Multilevel Regression and Poststratification with Stan
meta_img: /images/image.jpg
draft: true
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE, warning=FALSE, message=FALSE, 
                      results='show', cache=TRUE, autodep=TRUE)
```


## Introduction


Jonathan Kastellec has an excellent tutorial [at his website](http://www.princeton.edu/~jkastell/mrp_primer.html) using Multilevel Regression and Poststratification (MRP) using `r-base` tools and the `arm` package. I'd like to explore Jonathan's example using some new tools. First, I'd like to explore the limitations of his approximate multilevel model with `glmer`, comparing it to a `Stan` model, which explores the whole posterior using the `brms` package. 

Next, I want to compare the poststratified bayesian model to the disaggragated model.

Second, I'd like to tidy the workflow, especially using model tidying tools such as `broom` and [`tidybayes`](https://github.com/mjskay/tidybayes). 

Lastly, I want to work through some `R` mapping examples, using `albersusa` to visualize some of the results.

Austin Rochford has a similar treatment using [PyMC3](https://gist.github.com/AustinRochford/bfc20cb3262169b41b730bd9faf74477) that I recommend you check out for an alternative perspective. 


## Disaggragation

If our goal is to estimate state-level opinion, a simple way is to combine results from many different surveys and calculate the observed mean. 

```{r}
library(tidyverse)
library(lme4)
library(brms)
library(rstan)
library(httr)

rstan_options(auto_write=TRUE)
options(mc.cores=parallel::detectCores())
```

## The Data

```{r}
# marriage.data <- foreign::read.dta('gay_marriage_megapoll.dta',
#                                    convert.underscore=TRUE)
# Statelevel <- foreign::read.dta("state_level_update.dta",
#                                 convert.underscore = TRUE)
# Census <- foreign::read.dta("poststratification 2000.dta",
#                             convert.underscore = TRUE)
```
```{r}
# Statelevel <- Statelevel[order(Statelevel$sstate.initnum),]
# Census <- Census[order(Census$cstate),]
# Census$cstate.initnum <-  match(Census$cstate, Statelevel$sstate)
```


The first issue here is that survey respondants may not be in proportion to the actual population in the state. We can try to correct this with poststratification.

Second, the variance of undersampled groups is too large for an unbiased (observed) estimated mean to be useful. We can alleivate this by partial pooling used in multilevel regression.

Kastellec does a lot of variable recoding and in some ways I'm not sure the tidy way is much better, but we'll try:

```{r, echo=FALSE}
# marriage.data$race.female <- (marriage.data$female *3) + marriage.data$race.wbh
# marriage.data$age.edu.cat <- 4 * (marriage.data$age.cat -1) + marriage.data$edu.cat
# marriage.data$p.evang.full <- Statelevel$p.evang[marriage.data$state.initnum]
# marriage.data$p.mormon.full <-Statelevel$p.mormon[marriage.data$state.initnum]
# marriage.data$p.relig.full <- marriage.data$p.evang.full + marriage.data$p.mormon.full
# marriage.data$p.kerry.full <- Statelevel$kerry.04[marriage.data$state.initnum]
# 
# Census$crace.female <- (Census$cfemale *3) + Census$crace.WBH 
# Census$cage.edu.cat <- 4 * (Census$cage.cat -1) + Census$cedu.cat 
# Census$cp.evang.full<-  Statelevel$p.evang[Census$cstate.initnum]
# Census$cp.mormon.full <- Statelevel$p.mormon[Census$cstate.initnum]
# Census$cp.relig.full <- Census$cp.evang.full + Census$cp.mormon.full
# Census$cp.kerry.full <-  Statelevel$kerry.04[Census$cstate.initnum]
```


## Model 1: Disaggragation

```{r}
# marriage.opinion <- marriage.data %>%
#   group_by(statename) %>%
#   summarise(support = mean(yes.of.all))
# marriage.opinion
```

As an aside, I really dislike this coding scheme as it seems to make the interpretation of the categorical quantities very difficult to understand. I'd like to try an alternative reformulation of the indicators later, or have a function to convert them a la `tidybayes` to easily understand. 

Next, we code the system census in the same way.

## Models

```{r}
# approx.mod <- glmer(formula = yes.of.all ~ 
#                             (1|race.female) + (1|age.cat) +
#                             (1|edu.cat) + (1|age.edu.cat) + 
#                             (1|state) + (1|region) + (1|poll) +
#                             p.relig.full + p.kerry.full, 
#                           data=marriage.data, family=binomial(link="logit"))
# 
# bayes.mod <- brm(yes.of.all ~ (1|race.female) + (1|age.cat) + (1|edu.cat) 
#                  + (1|age.edu.cat) + (1|state) + (1|region) + (1|poll) 
#                  + p.relig.full + p.kerry.full, 
#                  data=marriage.data, family=bernoulli(),
#                  prior=c(set_prior("normal(0,1)", class='b'),
#                          set_prior("normal(0,1)", class='sd', group="race.female"),
#                          set_prior("normal(0,1)", class='sd', group="age.cat"),
#                          set_prior("normal(0,1)", class='sd', group="edu.cat"),
#                          set_prior("normal(0,1)", class='sd', group="age.edu.cat"),
#                          set_prior("normal(0,1)", class='sd', group="state"),
#                          set_prior("normal(0,1)", class='sd', group="region"),
#                          set_prior("normal(0,1)", class='sd', group="poll")))
```




## Full Bayesian

Let's look at the different variance estimations for group-level effects:

First, note that I didn't include the standard error from the MLE method. In general, this is [hard to do](https://stackoverflow.com/questions/31694812/standard-error-of-variance-component-from-the-output-of-lmer), but we get the percentile intervals for free with using `brms`. 

For example, parameter level standard errors require a bootstrap computation or likelihood ratio test. 




However, it isn't clear how this effects our estimation of state-level responses. Let's take a look at 


One comparison I like is what Matt Vuorre calls [with-subject scatterplots](https://mvuorre.github.io/post/2017/within-subject-scatter/). Although we are using them for a difference purpose here, the basic idea is really neat. Austin Rochford also uses a similar chart, but instead of dots I am going to plot the convenient two letter state abbreviation. 








