<!-- BLOGDOWN-HEAD -->
<!-- /BLOGDOWN-HEAD -->

<div id="TOC">
<ul>
<li><a href="#introduction">Introduction</a></li>
<li><a href="#the-data">The Data</a><ul>
<li><a href="#tidying-data">Tidying data</a></li>
</ul></li>
<li><a href="#model-1-disaggragation">Model 1: Disaggragation</a></li>
<li><a href="#model-2-maximum-likelihood-multilevel-model">Model 2: Maximum Likelihood Multilevel Model</a></li>
<li><a href="#model-3-full-bayesian-model">Model 3: Full Bayesian Model</a></li>
<li><a href="#model-comparisons">Model Comparisons</a></li>
</ul>
</div>

<div id="introduction" class="section level2">
<h2>Introduction</h2>
<p>In the last post I wrote the <a href="https://timmastny.netlify.com/blog/poststratification-with-dplyr/">“MRP Primer” Primer</a> studying the <em>p</em> part of MRP: poststratification. This post explores the actual <a href="http://www.princeton.edu/~jkastell/mrp_primer.html">MRP Primer by Jonathan Kastellec</a>. Jonathan and his coauthors wrote this excellent tutorial on Multilevel Regression and Poststratification (MRP) using <code>r-base</code> and <code>arm</code>/<code>lme4</code>.</p>
<p>Inspired by Austin Rochford’s full Bayesian implementation of the MRP Primer using <a href="https://gist.github.com/AustinRochford/bfc20cb3262169b41b730bd9faf74477">PyMC3</a>, I decided to approach the problem using R and <a href="http://mc-stan.org/">Stan</a>. In particular, I wanted to highlight two packages:</p>
<ul>
<li><p><a href="https://github.com/paul-buerkner/brms"><code>brms</code></a>, which provides a <code>lme4</code> like interface to Stan. And</p></li>
<li><p><a href="https://github.com/mjskay/tidybayes"><code>tidybayes</code></a>, which is a general tool for tidying Bayesian package outputs.</p></li>
</ul>
<p>Additionally, I’d like to compare the empirical mean disaggragated model, the maximum likelihood estimated multilevel model, the full Bayesian model.</p>
<p>Lastly, I’ll be doing some graphical map comparisons with the <code>albersusa</code> package.</p>
<p>Here’s what we’ll need to get started</p>
<pre class="r"><code>library(tidyverse)
library(lme4)
library(brms)
library(rstan)
library(albersusa)

rstan_options(auto_write=TRUE)
options(mc.cores=parallel::detectCores())</code></pre>
</div>
<div id="the-data" class="section level2">
<h2>The Data</h2>
<p>Here are the three data sets we’ll need. First the <code>marriage.data</code> is a compliation of gay marriage polls that we hope can give us a perspective on the support of gay marriage state by state. <code>Statelevel</code> provides some additional state information we’ll use as predictors in our model, such as the proportion of religious voters. And just like <a href="https://timmastny.netlify.com/blog/poststratification-with-dplyr/">last time</a>, the Census data will provide our poststratification weights.</p>
<pre class="r"><code>marriage.data &lt;- foreign::read.dta(&#39;gay_marriage_megapoll.dta&#39;,
                                   convert.underscore=TRUE)
Statelevel &lt;- foreign::read.dta(&quot;state_level_update.dta&quot;,
                                convert.underscore = TRUE)
Census &lt;- foreign::read.dta(&quot;poststratification 2000.dta&quot;,
                            convert.underscore = TRUE)</code></pre>
<div id="tidying-data" class="section level3">
<h3>Tidying data</h3>
<p>Here, I am proceeding just as Jonathan Kastellec. We want to code our demographic groups in a consistent way across our data so we can easily poststratify.</p>
<pre class="r"><code>Statelevel &lt;- Statelevel %&gt;% arrange(sstate.initnum)
Census &lt;- Census %&gt;% arrange(cstate)</code></pre>
<p>This section is copied straight from the MRP Primer. I’m not aware of a tidy way to handle this numerical coding of demographics. Let me know in the comments if you have some suggestions.</p>
<p>We’ll be joining the data based on the state number.</p>
<pre class="r"><code># add state level predictors to marriage.data
Statelevel &lt;- Statelevel %&gt;% rename(state.initnum = sstate.initnum)

marriage.data &lt;- Statelevel %&gt;%
  select(state.initnum, p.evang, p.mormon, kerry.04) %&gt;%
  right_join(marriage.data)

# Combine demographic groups
marriage.data &lt;- marriage.data %&gt;%
  mutate(race.female = (female * 3) + race.wbh) %&gt;%
  mutate(age.edu.cat = (female * 3) + race.wbh) %&gt;%
  mutate(p.relig = p.evang + p.mormon)

# add predictors
# Census$cstate.initnum &lt;-  match(Census$cstate, Statelevel$sstate)
# 
# Census$crace.female &lt;- (Census$cfemale * 3) + Census$crace.WBH
# Census$cage.edu.cat &lt;- 4 * (Census$cage.cat - 1) + Census$cedu.cat
# Census$cp.relig.full &lt;- Census$cp.evang.full + Census$cp.mormon.full
# 
# Census$cp.evang.full&lt;-  Statelevel$p.evang[Census$cstate.initnum]
# Census$cp.mormon.full &lt;- Statelevel$p.mormon[Census$cstate.initnum]
# 
# Census$cp.kerry.full &lt;-  Statelevel$kerry.04[Census$cstate.initnum]</code></pre>
</div>
</div>
<div id="model-1-disaggragation" class="section level2">
<h2>Model 1: Disaggragation</h2>
<pre class="r"><code>marriage.opinion &lt;- marriage.data %&gt;%
  group_by(statename) %&gt;%
  summarise(support = mean(yes.of.all))
marriage.opinion</code></pre>
<pre><code>## # A tibble: 50 x 2
##               statename   support
##                  &lt;fctr&gt;     &lt;dbl&gt;
##  1              alabama 0.1284404
##  2              arizona 0.4296875
##  3             arkansas 0.1071429
##  4           california 0.4624809
##  5             colorado 0.3923077
##  6          connecticut 0.3623188
##  7             delaware 0.1764706
##  8 district of columbia 0.2857143
##  9              florida 0.3227666
## 10              georgia 0.2692308
## # ... with 40 more rows</code></pre>
<p>As an aside, I really dislike this coding scheme as it seems to make the interpretation of the categorical quantities very difficult to understand. I’d like to try an alternative reformulation of the indicators later, or have a function to convert them a la <code>tidybayes</code> to easily understand.</p>
<p>Next, we code the system census in the same way.</p>
</div>
<div id="model-2-maximum-likelihood-multilevel-model" class="section level2">
<h2>Model 2: Maximum Likelihood Multilevel Model</h2>
<pre class="r"><code>approx.mod &lt;- glmer(formula = yes.of.all ~ (1|race.female) 
                    + (1|age.cat) + (1|edu.cat) + (1|age.edu.cat) 
                    + (1|state) + (1|region) + (1|poll) 
                    + p.relig + kerry.04,
                          data=marriage.data, family=binomial(link=&quot;logit&quot;))</code></pre>
<pre class="r"><code>summary(approx.mod)</code></pre>
<pre><code>## Generalized linear mixed model fit by maximum likelihood (Laplace
##   Approximation) [glmerMod]
##  Family: binomial  ( logit )
## Formula: yes.of.all ~ (1 | race.female) + (1 | age.cat) + (1 | edu.cat) +  
##     (1 | age.edu.cat) + (1 | state) + (1 | region) + (1 | poll) +  
##     p.relig + kerry.04
##    Data: marriage.data
## 
##      AIC      BIC   logLik deviance df.resid 
##   7460.9   7528.4  -3720.4   7440.9     6331 
## 
## Scaled residuals: 
##     Min      1Q  Median      3Q     Max 
## -2.2154 -0.7035 -0.4786  0.9909  3.8167 
## 
## Random effects:
##  Groups      Name        Variance Std.Dev.
##  state       (Intercept) 0.001607 0.04009 
##  age.edu.cat (Intercept) 0.033869 0.18403 
##  race.female (Intercept) 0.020344 0.14263 
##  poll        (Intercept) 0.042019 0.20499 
##  region      (Intercept) 0.038809 0.19700 
##  edu.cat     (Intercept) 0.131696 0.36290 
##  age.cat     (Intercept) 0.305043 0.55231 
## Number of obs: 6341, groups:  
## state, 49; age.edu.cat, 6; race.female, 6; poll, 5; region, 5; edu.cat, 4; age.cat, 4
## 
## Fixed effects:
##              Estimate Std. Error z value Pr(&gt;|z|)   
## (Intercept) -1.397288   0.541549  -2.580  0.00988 **
## p.relig     -0.015162   0.005003  -3.031  0.00244 **
## kerry.04     0.018107   0.006943   2.608  0.00911 **
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Correlation of Fixed Effects:
##          (Intr) p.relg
## p.relig  -0.544       
## kerry.04 -0.718  0.653
## convergence code: 0
## Model failed to converge with max|grad| = 0.00105747 (tol = 0.001, component 1)
## Model is nearly unidentifiable: large eigenvalue ratio
##  - Rescale variables?</code></pre>
<p>First, note that I didn’t include the standard error from the MLE method. In general, this is <a href="https://stackoverflow.com/questions/31694812/standard-error-of-variance-component-from-the-output-of-lmer">hard to do</a>, but we get the percentile intervals for free with using <code>brms</code>.</p>
</div>
<div id="model-3-full-bayesian-model" class="section level2">
<h2>Model 3: Full Bayesian Model</h2>
<pre class="r"><code>bayes.mod &lt;- brm(yes.of.all ~ (1|race.female) + (1|age.cat) + (1|edu.cat)
                 + (1|age.edu.cat) + (1|state) + (1|region) + (1|poll)
                 + p.relig + kerry.04,
                 data=marriage.data, family=bernoulli(),
                 prior=c(set_prior(&quot;normal(0,1)&quot;, class=&#39;b&#39;),
                         set_prior(&quot;normal(0,1)&quot;, class=&#39;sd&#39;, group=&quot;race.female&quot;),
                         set_prior(&quot;normal(0,1)&quot;, class=&#39;sd&#39;, group=&quot;age.cat&quot;),
                         set_prior(&quot;normal(0,1)&quot;, class=&#39;sd&#39;, group=&quot;edu.cat&quot;),
                         set_prior(&quot;normal(0,1)&quot;, class=&#39;sd&#39;, group=&quot;age.edu.cat&quot;),
                         set_prior(&quot;normal(0,1)&quot;, class=&#39;sd&#39;, group=&quot;state&quot;),
                         set_prior(&quot;normal(0,1)&quot;, class=&#39;sd&#39;, group=&quot;region&quot;),
                         set_prior(&quot;normal(0,1)&quot;, class=&#39;sd&#39;, group=&quot;poll&quot;)))</code></pre>
<pre><code>## 
## SAMPLING FOR MODEL &#39;bernoulli(logit) brms-model&#39; NOW (CHAIN 1).
## 
## Gradient evaluation took 0.015625 seconds
## 1000 transitions using 10 leapfrog steps per transition would take 156.25 seconds.
## Adjust your expectations accordingly!
## 
## 
## Iteration:    1 / 2000 [  0%]  (Warmup)
## Iteration:  200 / 2000 [ 10%]  (Warmup)
## Iteration:  400 / 2000 [ 20%]  (Warmup)
## Iteration:  600 / 2000 [ 30%]  (Warmup)
## Iteration:  800 / 2000 [ 40%]  (Warmup)
## Iteration: 1000 / 2000 [ 50%]  (Warmup)
## Iteration: 1001 / 2000 [ 50%]  (Sampling)
## Iteration: 1200 / 2000 [ 60%]  (Sampling)
## Iteration: 1400 / 2000 [ 70%]  (Sampling)
## Iteration: 1600 / 2000 [ 80%]  (Sampling)
## Iteration: 1800 / 2000 [ 90%]  (Sampling)
## Iteration: 2000 / 2000 [100%]  (Sampling)
## 
##  Elapsed Time: 424.734 seconds (Warm-up)
##                278.062 seconds (Sampling)
##                702.797 seconds (Total)
## 
## 
## SAMPLING FOR MODEL &#39;bernoulli(logit) brms-model&#39; NOW (CHAIN 2).
## 
## Gradient evaluation took 0.015625 seconds
## 1000 transitions using 10 leapfrog steps per transition would take 156.25 seconds.
## Adjust your expectations accordingly!
## 
## 
## Iteration:    1 / 2000 [  0%]  (Warmup)
## Iteration:  200 / 2000 [ 10%]  (Warmup)
## Iteration:  400 / 2000 [ 20%]  (Warmup)
## Iteration:  600 / 2000 [ 30%]  (Warmup)
## Iteration:  800 / 2000 [ 40%]  (Warmup)
## Iteration: 1000 / 2000 [ 50%]  (Warmup)
## Iteration: 1001 / 2000 [ 50%]  (Sampling)
## Iteration: 1200 / 2000 [ 60%]  (Sampling)
## Iteration: 1400 / 2000 [ 70%]  (Sampling)
## Iteration: 1600 / 2000 [ 80%]  (Sampling)
## Iteration: 1800 / 2000 [ 90%]  (Sampling)
## Iteration: 2000 / 2000 [100%]  (Sampling)
## 
##  Elapsed Time: 417.375 seconds (Warm-up)
##                277.891 seconds (Sampling)
##                695.266 seconds (Total)
## 
## 
## SAMPLING FOR MODEL &#39;bernoulli(logit) brms-model&#39; NOW (CHAIN 3).
## 
## Gradient evaluation took 0.015625 seconds
## 1000 transitions using 10 leapfrog steps per transition would take 156.25 seconds.
## Adjust your expectations accordingly!
## 
## 
## Iteration:    1 / 2000 [  0%]  (Warmup)
## Iteration:  200 / 2000 [ 10%]  (Warmup)
## Iteration:  400 / 2000 [ 20%]  (Warmup)
## Iteration:  600 / 2000 [ 30%]  (Warmup)
## Iteration:  800 / 2000 [ 40%]  (Warmup)
## Iteration: 1000 / 2000 [ 50%]  (Warmup)
## Iteration: 1001 / 2000 [ 50%]  (Sampling)
## Iteration: 1200 / 2000 [ 60%]  (Sampling)
## Iteration: 1400 / 2000 [ 70%]  (Sampling)
## Iteration: 1600 / 2000 [ 80%]  (Sampling)
## Iteration: 1800 / 2000 [ 90%]  (Sampling)
## Iteration: 2000 / 2000 [100%]  (Sampling)
## 
##  Elapsed Time: 433.875 seconds (Warm-up)
##                279 seconds (Sampling)
##                712.875 seconds (Total)
## 
## 
## SAMPLING FOR MODEL &#39;bernoulli(logit) brms-model&#39; NOW (CHAIN 4).
## 
## Gradient evaluation took 0 seconds
## 1000 transitions using 10 leapfrog steps per transition would take 0 seconds.
## Adjust your expectations accordingly!
## 
## 
## Iteration:    1 / 2000 [  0%]  (Warmup)
## Iteration:  200 / 2000 [ 10%]  (Warmup)
## Iteration:  400 / 2000 [ 20%]  (Warmup)
## Iteration:  600 / 2000 [ 30%]  (Warmup)
## Iteration:  800 / 2000 [ 40%]  (Warmup)
## Iteration: 1000 / 2000 [ 50%]  (Warmup)
## Iteration: 1001 / 2000 [ 50%]  (Sampling)
## Iteration: 1200 / 2000 [ 60%]  (Sampling)
## Iteration: 1400 / 2000 [ 70%]  (Sampling)
## Iteration: 1600 / 2000 [ 80%]  (Sampling)
## Iteration: 1800 / 2000 [ 90%]  (Sampling)
## Iteration: 2000 / 2000 [100%]  (Sampling)
## 
##  Elapsed Time: 494.203 seconds (Warm-up)
##                302.219 seconds (Sampling)
##                796.422 seconds (Total)</code></pre>
</div>
<div id="model-comparisons" class="section level2">
<h2>Model Comparisons</h2>
<p>One comparison I like is what Matt Vuorre calls <a href="https://mvuorre.github.io/post/2017/within-subject-scatter/">with-subject scatterplots</a>. Although we are using them for a difference purpose here, the basic idea is really neat. Austin Rochford also uses a similar chart, but instead of dots I am going to plot the <a href="http://andrewgelman.com/2009/01/14/state-by-state/">two letter</a> <a href="http://andrewgelman.com/2014/05/16/gullibility-effect-using-state-level-correlations-draw-pretty-much-conclusion-want-individual-level-causation/">state abbreviation</a>.</p>
</div>
