---
title: MRP Using brms and tidybayes
author: ~
date: '2017-11-20'
slug: multilevel-mrp-tidybayes-brms-stan
categories: []
tags: []
description: Multilevel Regression and Poststratification with Stan
meta_img: /images/image.jpg
output:
  blogdown::html_page:
    toc: true
---


<div id="TOC">
<ul>
<li><a href="#introduction">Introduction</a></li>
<li><a href="#the-data">The Data</a><ul>
<li><a href="#tidying-variables">Tidying Variables</a></li>
<li><a href="#tidying-poststratification">Tidying Poststratification</a></li>
</ul></li>
<li><a href="#model-1-disaggragation">Model 1: Disaggragation</a></li>
<li><a href="#model-2-maximum-likelihood-multilevel-model">Model 2: Maximum Likelihood Multilevel Model</a></li>
<li><a href="#model-3-full-bayesian-model">Model 3: Full Bayesian Model</a></li>
<li><a href="#model-comparisons">Model Comparisons</a></li>
</ul>
</div>

<div id="introduction" class="section level2">
<h2>Introduction</h2>
<p>In the last post I wrote the <a href="https://timmastny.rbind.io/blog/poststratification-with-dplyr/">“MRP Primer” Primer</a> studying the <em>p</em> part of MRP: poststratification. This post explores the actual <a href="http://www.princeton.edu/~jkastell/mrp_primer.html">MRP Primer by Jonathan Kastellec</a>. Jonathan and his coauthors wrote this excellent tutorial on Multilevel Regression and Poststratification (MRP) using <code>r-base</code> and <code>arm</code>/<code>lme4</code>.</p>
<p>The aim of the MRP Primer is to estimate state level opinions for gay marriage based on a potentially non-representative survey data. That requires poststratification. As was done in the last post, we are going to use external Census data to scale the average support of each demographic group in proportion to its percentage of the state population.</p>
<p>Previously, we used empirical means to find the average demographic group support. Here, we’ll use multilevel regression which has <a href="http://andrewgelman.com/2014/01/21/everything-need-know-bayesian-statistics-learned-eight-schools/">well documented advantages</a> to compared to empirical means and traditional regression models. These multilevel models allow us to partially pool information across similar groups, providing better estimates for groups with sparse (or even non-existent) data.</p>
<p>Inspired by Austin Rochford’s full Bayesian implementation of the MRP Primer using <a href="https://gist.github.com/AustinRochford/bfc20cb3262169b41b730bd9faf74477">PyMC3</a>, I decided to approach the problem using R and <a href="http://mc-stan.org/">Stan</a>. In particular, I wanted to highlight two packages:</p>
<ul>
<li><p><a href="https://github.com/paul-buerkner/brms"><code>brms</code></a>, which provides a <code>lme4</code> like interface to Stan. And</p></li>
<li><p><a href="https://github.com/mjskay/tidybayes"><code>tidybayes</code></a>, which is a general tool for tidying Bayesian package outputs.</p></li>
</ul>
<p>Additionally, I’d like to do a three-way comparison between the empirical mean disaggregated model, the maximum likelihood estimated multilevel model, the full Bayesian model. This includes some graphical map comparisons with the <code>albersusa</code> package.</p>
<p>Here’s what we’ll need to get started</p>
<pre class="r"><code>library(tidyverse)
library(lme4)
library(brms)
library(rstan)
library(albersusa)
library(cowplot)
library(forcats)

rstan_options(auto_write=TRUE)
options(mc.cores=parallel::detectCores())</code></pre>
</div>
<div id="the-data" class="section level2">
<h2>The Data</h2>
<p>Here are the three data sets we’ll need. First the <code>marriage.data</code> is a compilation of gay marriage polls that we hope can give us a perspective on the support of gay marriage state by state. <code>Statelevel</code> provides some additional state information we’ll use as predictors in our model, such as the proportion of religious voters. And just like <a href="https://timmastny.rbind.io/blog/poststratification-with-dplyr/">last time</a>, the Census data will provide our poststratification weights.</p>
<pre class="r"><code>marriage.data &lt;- foreign::read.dta(&#39;gay_marriage_megapoll.dta&#39;,
                                   convert.underscore=TRUE)
Statelevel &lt;- foreign::read.dta(&quot;state_level_update.dta&quot;,
                                convert.underscore = TRUE)
Census &lt;- foreign::read.dta(&quot;poststratification 2000.dta&quot;,
                            convert.underscore = TRUE)</code></pre>
<div id="tidying-variables" class="section level3">
<h3>Tidying Variables</h3>
<p>The MRP Primer takes a very literal, <code>r-base</code> approach to recoding the demographic variables and combining data across data frames. Here, I try to <a href="https://cran.r-project.org/web/packages/tidyr/vignettes/tidy-data.html">tidy</a> the data, based on the philosophy and tools of the <code>tidyverse</code> collection of packages. Personally, I think cleaning the data in this manner is simpler and more descriptive of the tidying goals.</p>
<pre class="r"><code># add state level predictors to marriage.data
Statelevel &lt;- Statelevel %&gt;% rename(state = sstate)

marriage.data &lt;- Statelevel %&gt;%
  select(state, p.evang, p.mormon, kerry.04) %&gt;%
  right_join(marriage.data)

# Combine demographic groups
marriage.data &lt;- marriage.data %&gt;%
  mutate(race.female = (female * 3) + race.wbh) %&gt;%
  mutate(age.edu.cat = 4 * (age.cat - 1) + edu.cat) %&gt;%
  mutate(p.relig = p.evang + p.mormon)</code></pre>
</div>
<div id="tidying-poststratification" class="section level3">
<h3>Tidying Poststratification</h3>
<p>Now that the data is broken down into the demographic groups, the next step is to find the percentage of the total state population for each group so we can poststratify. We want to code the Census demographics in the same way as in the gay marriage polls so we can</p>
<pre class="r"><code># change column names for natural join with marriage.data
Census &lt;- Census %&gt;% 
  rename(state = cstate,
         age.cat = cage.cat,
         edu.cat = cedu.cat,
         region = cregion)

Census &lt;- Statelevel %&gt;%
  select(state, p.evang, p.mormon, kerry.04) %&gt;%
  right_join(Census)

Census &lt;- Census %&gt;%
  mutate(race.female = (cfemale * 3 ) + crace.WBH) %&gt;%
  mutate(age.edu.cat = 4 * (age.cat - 1) + edu.cat) %&gt;%
  mutate(p.relig = p.evang + p.mormon)</code></pre>
<p>Then we can just include the Census rates as a column in the gay marriage poll data.</p>
<pre class="r"><code># marriage.data &lt;- Census %&gt;%
#   select(state, kerry.04, race.female, age.edu.cat)</code></pre>
</div>
</div>
<div id="model-1-disaggragation" class="section level2">
<h2>Model 1: Disaggragation</h2>
<p>The first model we’ll build is the disaggregate model. This model simply calculates the averages in each state by taking the mean of responses within each state.</p>
<pre class="r"><code>mod.disag &lt;- marriage.data %&gt;%
  group_by(state) %&gt;%
  summarise(support = mean(yes.of.all)) %&gt;%
  mutate(model = &quot;no_ps&quot;)</code></pre>
<p>This simplicity comes at a cost. As demonstrated in the previous post, the empirical mean is not representative of the actual state mean if the respondents within are not in proportion to each group’s percentage of the total population. So let’s build the poststratified disaggregated model.</p>
<p>First we’ll find the average of within each group:</p>
<pre class="r"><code>grp.means &lt;- marriage.data %&gt;%
  group_by(state, region, race.female, age.cat, 
           edu.cat, age.edu.cat, p.relig, kerry.04) %&gt;%
  summarise(support = mean(yes.of.all, na.rm=TRUE))</code></pre>
<p>Then we’ll add in the group’s percentage in each state:</p>
<pre class="r"><code>grp.means &lt;- Census %&gt;%
  select(state, age.cat, edu.cat, region, kerry.04,
         race.female, age.edu.cat, p.relig, cpercent.state) %&gt;%
  right_join(grp.means)</code></pre>
<p>Then we’ll sum the scaled group averages and get the total state averages:</p>
<pre class="r"><code>mod.disag.ps &lt;- grp.means %&gt;%
  group_by(state) %&gt;%
  summarise(support = sum(support * cpercent.state, na.rm=TRUE)) %&gt;%
  mutate(model = &quot;ps&quot;)</code></pre>
<p>Here’s the difference:</p>
<pre class="r"><code>disag.point &lt;- bind_rows(mod.disag, mod.disag.ps) %&gt;%
  group_by(model) %&gt;%
  arrange(support, .by_group=TRUE) %&gt;%
  filter(state != &quot;&quot;) %&gt;%
  ggplot(aes(x = support, y=forcats::fct_inorder(state), color=model)) + 
  geom_point() + 
  theme_classic() + theme(legend.position = &#39;none&#39;) +  
  directlabels::geom_dl(aes(label=model), method=&#39;smart.grid&#39;) +
  ylab(&#39;state&#39;)

disag.scat &lt;- bind_cols(mod.disag, mod.disag.ps) %&gt;%
  filter(state != &quot;&quot;) %&gt;%
  ggplot(aes(x = support, y=support1)) + 
  geom_text(aes(label=state), hjust=0.5, vjust=0.25) +
  geom_abline(slope = 1, intercept = 0) +
  xlim(c(0,0.7)) + ylim(c(0,0.7)) + 
  xlab(&quot;support&quot;) + ylab(&quot;poststrat support&quot;) +
  coord_fixed()

plot_grid(disag.point, disag.scat)</code></pre>
<p><img src="/blog/2017-11-19-multilevel-mrp-tidybayes-brms-stan_files/figure-html/unnamed-chunk-10-1.png" width="672" /></p>
<p>*** try ggcow subset within subject plot</p>
<p>And here’s the problem:</p>
<pre class="r"><code>grp.means %&gt;%
  group_by(state) %&gt;%
  summarise(total_percent = sum(cpercent.state, na.rm=TRUE)) %&gt;%
  filter(state != &quot;&quot;) %&gt;%
  ggplot(aes(x = state, y = total_percent)) +
  geom_point() +
  theme(axis.text.x=element_blank(),
        axis.ticks.x=element_blank()) + 
  coord_fixed(ratio=8)</code></pre>
<p><img src="/blog/2017-11-19-multilevel-mrp-tidybayes-brms-stan_files/figure-html/unnamed-chunk-11-1.png" width="672" /></p>
<p>The lack of data for some voter groups makes poststratifying on the state level impossible and/or meaningless. This scenario actually motivates multilevel regression. As we’ll see in the next section, the multilevel model assumes similar demographic groups tend to vote the same. For example, suppose no black women were polled in South Dakota. Instead of producing skewed estimates, we can estimate the proportion of support black women have for gay marriage in South Dakota by level of support (and variation of support) black women have in all other states.</p>
</div>
<div id="model-2-maximum-likelihood-multilevel-model" class="section level2">
<h2>Model 2: Maximum Likelihood Multilevel Model</h2>
<pre class="r"><code>approx.mod &lt;- glmer(formula = yes.of.all ~ (1|race.female)
                    + (1|age.cat) + (1|edu.cat) + (1|age.edu.cat)
                    + (1|state) + (1|region) + (1|poll)
                    + p.relig + kerry.04,
                    data=marriage.data, family=binomial(link=&quot;logit&quot;))</code></pre>
<pre class="r"><code>summary(approx.mod)</code></pre>
<pre><code>## Generalized linear mixed model fit by maximum likelihood (Laplace
##   Approximation) [glmerMod]
##  Family: binomial  ( logit )
## Formula: yes.of.all ~ (1 | race.female) + (1 | age.cat) + (1 | edu.cat) +  
##     (1 | age.edu.cat) + (1 | state) + (1 | region) + (1 | poll) +  
##     p.relig + kerry.04
##    Data: marriage.data
## 
##      AIC      BIC   logLik deviance df.resid 
##   7459.4   7527.0  -3719.7   7439.4     6331 
## 
## Scaled residuals: 
##    Min     1Q Median     3Q    Max 
## -2.166 -0.705 -0.477  0.981  3.883 
## 
## Random effects:
##  Groups      Name        Variance Std.Dev.
##  state       (Intercept) 0.001333 0.03651 
##  age.edu.cat (Intercept) 0.007711 0.08782 
##  race.female (Intercept) 0.054568 0.23360 
##  poll        (Intercept) 0.042179 0.20538 
##  region      (Intercept) 0.038087 0.19516 
##  edu.cat     (Intercept) 0.129593 0.35999 
##  age.cat     (Intercept) 0.306974 0.55405 
## Number of obs: 6341, groups:  
## state, 49; age.edu.cat, 16; race.female, 6; poll, 5; region, 5; edu.cat, 4; age.cat, 4
## 
## Fixed effects:
##              Estimate Std. Error z value Pr(&gt;|z|)   
## (Intercept) -1.406648   0.541263  -2.599  0.00935 **
## p.relig     -0.015250   0.004991  -3.056  0.00225 **
## kerry.04     0.018259   0.006924   2.637  0.00836 **
## ---
## Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1
## 
## Correlation of Fixed Effects:
##          (Intr) p.relg
## p.relig  -0.543       
## kerry.04 -0.717  0.653</code></pre>
<p>First, note that I didn’t include the standard error from the MLE method. In general, this is <a href="https://stackoverflow.com/questions/31694812/standard-error-of-variance-component-from-the-output-of-lmer">hard to do</a>, but we get the percentile intervals for free with using <code>brms</code>.</p>
</div>
<div id="model-3-full-bayesian-model" class="section level2">
<h2>Model 3: Full Bayesian Model</h2>
<pre class="r"><code>bayes.mod &lt;- brm(yes.of.all ~ (1|race.female) + (1|age.cat) + (1|edu.cat)
                 + (1|age.edu.cat) + (1|state) + (1|region) + (1|poll)
                 + p.relig + kerry.04,
                 data=marriage.data, family=bernoulli(),
                 prior=c(set_prior(&quot;normal(0,0.2)&quot;, class=&#39;b&#39;),
                         set_prior(&quot;normal(0,0.2)&quot;, class=&#39;sd&#39;, group=&quot;race.female&quot;),
                         set_prior(&quot;normal(0,0.2)&quot;, class=&#39;sd&#39;, group=&quot;age.cat&quot;),
                         set_prior(&quot;normal(0,0.2)&quot;, class=&#39;sd&#39;, group=&quot;edu.cat&quot;),
                         set_prior(&quot;normal(0,0.2)&quot;, class=&#39;sd&#39;, group=&quot;age.edu.cat&quot;),
                         set_prior(&quot;normal(0,0.2)&quot;, class=&#39;sd&#39;, group=&quot;state&quot;),
                         set_prior(&quot;normal(0,0.2)&quot;, class=&#39;sd&#39;, group=&quot;region&quot;),
                         set_prior(&quot;normal(0,0.2)&quot;, class=&#39;sd&#39;, group=&quot;poll&quot;)))</code></pre>
<pre class="r"><code>summary(bayes.mod)</code></pre>
<pre><code>##  Family: bernoulli 
##   Links: mu = logit 
## Formula: yes.of.all ~ (1 | race.female) + (1 | age.cat) + (1 | edu.cat) + (1 | age.edu.cat) + (1 | state) + (1 | region) + (1 | poll) + p.relig + kerry.04 
##    Data: marriage.data (Number of observations: 6341) 
## Samples: 4 chains, each with iter = 2000; warmup = 1000; thin = 1; 
##          total post-warmup samples = 4000
##     ICs: LOO = NA; WAIC = NA; R2 = NA
##  
## Group-Level Effects: 
## ~age.cat (Number of levels: 4) 
##               Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
## sd(Intercept)     0.42      0.09     0.26     0.63       3214 1.00
## 
## ~age.edu.cat (Number of levels: 16) 
##               Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
## sd(Intercept)     0.10      0.06     0.01     0.25       1457 1.00
## 
## ~edu.cat (Number of levels: 4) 
##               Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
## sd(Intercept)     0.32      0.09     0.17     0.52       3115 1.00
## 
## ~poll (Number of levels: 5) 
##               Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
## sd(Intercept)     0.22      0.07     0.11     0.40       2334 1.00
## 
## ~race.female (Number of levels: 6) 
##               Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
## sd(Intercept)     0.24      0.07     0.12     0.41       2425 1.00
## 
## ~region (Number of levels: 5) 
##               Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
## sd(Intercept)     0.22      0.08     0.10     0.42       4000 1.00
## 
## ~state (Number of levels: 49) 
##               Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
## sd(Intercept)     0.06      0.04     0.00     0.16       1738 1.00
## 
## Population-Level Effects: 
##           Estimate Est.Error l-95% CI u-95% CI Eff.Sample Rhat
## Intercept    -1.39      0.53    -2.42    -0.34       2695 1.00
## p.relig      -0.02      0.01    -0.03    -0.01       4000 1.00
## kerry.04      0.02      0.01     0.00     0.03       4000 1.00
## 
## Samples were drawn using sampling(NUTS). For each parameter, Eff.Sample 
## is a crude measure of effective sample size, and Rhat is the potential 
## scale reduction factor on split chains (at convergence, Rhat = 1).</code></pre>
</div>
<div id="model-comparisons" class="section level2">
<h2>Model Comparisons</h2>
<p>One comparison I like is what Matt Vuorre calls <a href="https://mvuorre.github.io/post/2017/within-subject-scatter/">with-subject scatterplots</a>. Although we are using them for a difference purpose here, the basic idea is really neat. Austin Rochford also uses a similar chart, but instead of dots I am going to plot the <a href="http://andrewgelman.com/2009/01/14/state-by-state/">two letter</a> <a href="http://andrewgelman.com/2014/05/16/gullibility-effect-using-state-level-correlations-draw-pretty-much-conclusion-want-individual-level-causation/">state abbreviation</a>.</p>
</div>
